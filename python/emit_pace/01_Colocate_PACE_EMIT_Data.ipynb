{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find PACE and EMIT granules overlapping in time and space\n",
    "Adapted from VITALS \"Finding Concurrent ECOSTRESS and EMIT Data\" tutorial located [here](https://nasa.github.io/VITALS/python/01_Finding_Concurrent_Data.html).\n",
    "\n",
    "Adapted for PACE by: Skye Caplan (NASA, SSAI)\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "An [Earthdata Login][edl] account is required to access data from the NASA Earthdata system, including NASA PACE and EMIT data.\n",
    "\n",
    "</div>\n",
    "\n",
    "[edl]: https://urs.earthdata.nasa.gov/\n",
    "[oci-data-access]: https://oceancolor.gsfc.nasa.gov/resources/docs/tutorials/notebooks/oci_data_access/\n",
    "[emit-data-access]: https://nasa.github.io/VITALS/python/Exploring_EMIT_L2A_RFL.html\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook will use `earthacces` and metadata in EMIT and PACE files' attributes to find overlapping granules both in space and within a certain time interval. \n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "At the end of this notebook, you will know how to:\n",
    "- Search for both PACE and EMIT data\n",
    "- Filter those search results to find concurrent datasets based on overpass time, cloud cover, etc.\n",
    "- Download only the datasets which match your filter criteria. \n",
    "\n",
    "## Contents\n",
    "1. [Setup](#1.-Setup)\n",
    "2. [Filtering Data](#2.-Filtering-Data)\n",
    "3. [Download or Stream Data](#3.-Download-or-Stream-Data)\n",
    "\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "Begin by importing all of the packages used in this notebook. PACE OCI has many data products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "import folium\n",
    "import earthaccess\n",
    "import warnings\n",
    "import folium.plugins\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np \n",
    "\n",
    "from branca.element import Figure\n",
    "from IPython.display import display\n",
    "from shapely import geometry\n",
    "from skimage import io\n",
    "from datetime import timedelta\n",
    "from shapely.geometry.polygon import orient\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells use `earthaccess` to configure and persist Earthdata login credentials, then establish the parameters used for the data search. Specifically, we set the time range, define the region of interest (ROI), and specify the target products. In this example, we searched for concurrent reflectance data from both EMIT and PACE sensors.\n",
    "Note that there are two PACE product suites listed in the `prods` list, [`PACE_OCI_L2_SFREFL`](https://doi.org/10.5067/PACE/OCI/L2/SFREFL/3.1) and `PACE_OCI_L2_SFREFL_NRT`. `NRT` in `PACE_OCI_L2_SFREFL_NRT` stands for Near Real Time, which is the collection including the most recent data (~1-2 months from present day). `PACE_OCI_L2_SFREFL` is for Refined data, which has been reprocessed with the best available ancillary data. More information can be found in the [SFREFL ATBD](https://www.earthdata.nasa.gov/apt/documents/sfrefl/v1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = earthaccess.login(persist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up search params for datasets\n",
    "\n",
    "# Temporal range\n",
    "tspan = ('2024-12-01','2025-02-01')\n",
    "# Bounding box is adjusted to the format earthaccess requires\n",
    "roi_bounds = (128, -30, 134, -23) #wsen\n",
    "bbox = geometry.box(*roi_bounds, ccw=True)\n",
    "roi = list(bbox.exterior.coords)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(index=[0], crs='epsg:4326', geometry=[bbox])\n",
    "\n",
    "# Data collections to search\n",
    "prods = [\"PACE_OCI_L2_SFREFL\", \"PACE_OCI_L2_SFREFL_NRT\", \"EMITL2ARFL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab results from Earthdata\n",
    "results = earthaccess.search_data(\n",
    "    short_name=prods,\n",
    "    polygon=roi,\n",
    "    temporal=tspan,\n",
    "    count=500\n",
    ")\n",
    "\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can examine the results of our search, The result returned approximately 200 granules for this case. Because not all of these granules overlap spatially or temporally, we further filter the results to retain only those that overlap with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filtering Data\n",
    "\n",
    "The returned results are converted to a dataframe and converted to a GeoDataframe. Next, only the colummns needed are kept and renamed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe of Results Metadata\n",
    "results_df = pd.json_normalize(results)\n",
    "# Create shapely polygons for result\n",
    "geometries = [utils.get_shapely_object(results[index]) for index in results_df.index.to_list()]\n",
    "# Convert to GeoDataframe\n",
    "gdf = gpd.GeoDataFrame(results_df, geometry=geometries, crs=\"EPSG:4326\")\n",
    "# Remove results df, no longer needed\n",
    "# del results_df\n",
    "# Add browse imagery links\n",
    "gdf['browse'] = [utils.get_png(granule) for granule in results]\n",
    "gdf['shortname'] = [result['umm']['CollectionReference']['ShortName'] for result in results]\n",
    "# Preview GeoDataframe\n",
    "print(f'{gdf.shape[0]} granules total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of columns to keep\n",
    "keep_cols = ['meta.concept-id','meta.native-id', 'umm.TemporalExtent.RangeDateTime.BeginningDateTime',\n",
    "             'umm.TemporalExtent.RangeDateTime.EndingDateTime','umm.CloudCover','umm.DataGranule.DayNightFlag',\n",
    "             'geometry','browse', 'shortname']\n",
    "# Remove unneeded columns\n",
    "gdf = gdf[gdf.columns.intersection(keep_cols)]\n",
    "# Rename some Columns\n",
    "gdf.rename(columns = {'meta.concept-id':'concept_id','meta.native-id':'granule',\n",
    "                       'umm.TemporalExtent.RangeDateTime.BeginningDateTime':'start_datetime',\n",
    "                      'umm.TemporalExtent.RangeDateTime.EndingDateTime':'end_datetime',\n",
    "                      'umm.CloudCover':'cloud_cover',\n",
    "                      'umm.DataGranule.DayNightFlag':'day_night'}, inplace=True)\n",
    "gdf['datetime_obj'] = pd.to_datetime(gdf['start_datetime'], format='ISO8601')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe is separated into two dataframes, one including the EMIT granules and the other one for PACE granules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Setting with Copy Warning - not applicable in this use case\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Split into two dataframes - ECO and EMIT\n",
    "pace_gdf = gdf[gdf['granule'].str.contains('OCI')]\n",
    "emit_gdf = gdf[gdf['granule'].str.contains('EMIT')]\n",
    "print(f' PACE OCI Granules: {pace_gdf.shape[0]} \\n EMIT Granules: {emit_gdf.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe is updated to only keep the rows with an existing intersection with EMIT granules. A new Colum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create new column based on intersection with union of EMIT polygons.\n",
    "pace_gdf['intersects'] = pace_gdf.intersects(emit_gdf.union_all())\n",
    "## Apply subsetting\n",
    "pace_gdf = pace_gdf[pace_gdf['intersects'] == True]\n",
    "print(f' PACE OCI Granules: {pace_gdf.shape[0]} \\n EMIT Granules: {emit_gdf.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pace_gdf, emit_gdf = utils.concurrent_match(pace_gdf,emit_gdf, col_name='datetime_obj',time_delta=timedelta(minutes=60))\n",
    "print(f' PACE OCI Granules: {pace_gdf.shape[0]} \\n EMIT Granules: {emit_gdf.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can plot our very reduced list of granules to see what we're left with. We want to make sure the PACE and EMIT granules we select have optimal conditions within themselves (e.g., clouds, no bad data, etc.), but also between sensors as well. EMIT granules are much smaller than one PACE OCI scene, and it's possible some of the EMIT data in our filtered list could overlap with PACE OCI at the edge of its swath, where L2 OCI pixels are expected to have greater angular effects. To minimize these effects, it's preferable to choose EMIT granules closer to the centre of an OCI scene, which the Folium map below is very useful for determining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Using Folium\n",
    "# Function to convert a bounding box for use in leaflet notation\n",
    "\n",
    "# Create Figure and Select Background Tiles\n",
    "fig = Figure(width=\"750px\", height=\"375px\")\n",
    "map1 = folium.Map(tiles='https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}', attr='Google')\n",
    "fig.add_child(map1)\n",
    "\n",
    "# Plot STAC ECOSTRESS Results - note we must drop the datetime_obj columns for this to work\n",
    "pace_gdf.drop(columns=['datetime_obj']).explore(\n",
    "    \"granule\",\n",
    "    categorical=True,\n",
    "    tooltip=[\n",
    "        \"granule\",\n",
    "        \"start_datetime\",\n",
    "        \"cloud_cover\",\n",
    "    ],\n",
    "    popup=True,\n",
    "    style_kwds=dict(fillOpacity=0.1, width=2),\n",
    "    name=\"PACE OCI\",\n",
    "    m=map1,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# Plot STAC EMITL2ARFL Results - note we must drop the datetime_obj columns for this to work\n",
    "emit_gdf.drop(columns=['datetime_obj']).explore(\n",
    "    \"granule\",\n",
    "    categorical=True,\n",
    "    tooltip=[\n",
    "        \"granule\",\n",
    "        \"start_datetime\",\n",
    "        \"cloud_cover\",\n",
    "    ],\n",
    "    popup=True,\n",
    "    style_kwds=dict(fillOpacity=0.1, width=2),\n",
    "    name=\"EMIT\",\n",
    "    m=map1,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "\n",
    "folium.GeoJson(bbox,\n",
    "                name='bounding_box',\n",
    "                ).add_to(map1)\n",
    "\n",
    "map1.fit_bounds(bounds=utils.convert_bounds(gdf.union_all().bounds))\n",
    "map1.add_child(folium.LayerControl())\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, we also want to make sure the data isn't filled with NaNs. From the map, it looks like January 17th is a good day for both EMIT and PACE, and the EMIT granules are relatively close to centre swath. We can print out the browse imagery for that day and decide which EMIT granules to keep for our final stream/download. \n",
    "\n",
    "PACE OCI browse imagery is coming soon, and once available, we will be able to quickly visualize the imagery in the same way to ensure initial data quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by granule\n",
    "pace_0117 = pace_gdf[(pace_gdf['granule'].str.contains(\"20250117T044314\")) & ~(pace_gdf['granule'].str.contains(\"NRT\"))]\n",
    "emit_0117 = emit_gdf[emit_gdf['granule'].str.contains(\"20250117\")]\n",
    "\n",
    "cols = 3\n",
    "rows = int(np.ceil(len(emit_0117)/cols))\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for _n, index in enumerate(emit_0117.index.to_list()):\n",
    "    img = io.imread(emit_0117['browse'][index])\n",
    "    ax[_n].imshow(img)\n",
    "    ax[_n].set_title(f\"Index: {index} - {emit_0117['granule'][index]}\")\n",
    "    ax[_n].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll keep 5 granules from the above selection, and put them in a final `filtered_results` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out granules to keep\n",
    "good_grans = [78,80,81,87,90] # Index numbers\n",
    "emit_0117_grans = emit_0117[emit_0117.index.isin(good_grans)]\n",
    "keep_granules = pace_0117.index.to_list()+emit_0117_grans.index.to_list()\n",
    "keep_granules.sort()\n",
    "\n",
    "filtered_results = [result for i, result in enumerate(results) if i in keep_granules]\n",
    "filtered_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download or Stream Data\n",
    "\n",
    "Now that we have all the links for the data we want, we can either stream or download the files, depending on user preference. we can download all the files using `earthaccess.download(filtered_results, local_path=\"data\")` or further filter the files to only downlaod the files we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download with earthaccess\n",
    "emit_files = [filtered_results[1],filtered_results[2]]\n",
    "pace_files = [filtered_results[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only get the EMIT RFL file and exclude the mask and uncertainty\n",
    "emit_rfl = [result.data_links()[0] for result in emit_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthaccess.download(pace_files, local_path=\"data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthaccess.download(emit_rfl, local_path=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the datasets are downloaded! Please proceed to the next tutorial in this series to learn how to open, explore, and regrid the scenes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
